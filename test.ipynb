{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advertising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.read_csv('datasets/raw/Advertising.csv', sep=',', encoding='utf-8')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = smf.ols(formula=\"Sales~TV+Newspaper+Radio\", data = df).fit()\n",
    "lm.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bondad de Ajsute más alta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = smf.ols(formula=\"Sales~TV\", data = df).fit()\n",
    "lm.rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = smf.ols(formula=\"Sales~Newspaper\", data = df).fit()\n",
    "lm.rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = smf.ols(formula=\"Sales~Radio\", data = df).fit()\n",
    "lm.rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insurance.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('datasets/raw/insurance.csv', sep=',', encoding='utf-8')\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapear valores de la columna 'sex'\n",
    "df2['sex'] = df2['sex'].map({'female': 1, 'male': 2})\n",
    "\n",
    "# Mapear valores de la columna 'smoker'\n",
    "df2['smoker'] = df2['smoker'].map({'yes': 1, 'no': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm2 = smf.ols(formula=\"charges~age+sex+bmi+children+smoker\", data = df2).fit()\n",
    "lm2.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML_houses_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3= pd.read_csv('datasets/raw/ML_Houses_dataset.csv', sep=',', encoding='utf-8')\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las columnas numéricas y categóricas\n",
    "numeric_columns = df3.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_columns = df3.select_dtypes(include=['object']).columns\n",
    "# Convertir las columnas categóricas a tipo str\n",
    "df3[categorical_columns] = df3[categorical_columns].astype(str)\n",
    "\n",
    "# Definir las transformaciones para las columnas numéricas\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Definir las transformaciones para las columnas categóricas\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Crear la columna transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Crear la pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "# Aplicar la pipeline al DataFrame\n",
    "transformed_df = pipeline.fit_transform(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las columnas numéricas y categóricas después de la transformación\n",
    "numeric_columns_transformed = pipeline.named_steps['preprocessor'].transformers_[0][1]['scaler'].get_feature_names_out(input_features=numeric_columns)\n",
    "categorical_columns_transformed = pipeline.named_steps['preprocessor'].transformers_[1][1]['onehot'].get_feature_names_out(input_features=categorical_columns)\n",
    "\n",
    "# Unir los nombres de las columnas numéricas y categóricas después de la transformación\n",
    "all_columns_transformed = np.concatenate([numeric_columns_transformed, categorical_columns_transformed])\n",
    "\n",
    "# Convertir el array transformado a un DataFrame con los nuevos nombres de columnas\n",
    "transformed_df_2 = pd.DataFrame(transformed_df.toarray(), columns=all_columns_transformed)\n",
    "transformed_df_2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df_2.to_csv('datasets/raw/transformed_df_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_houses = transformed_df_2[['GrLivArea', 'BedroomAbvGr', 'KitchenAbvGr', 'OverallCond','Pesos', 'Alley_Grvl','Alley_Pave','Alley_nan', 'WallMat_Concrete','WallMat_Wood','WallMat_nan','SalePrice']]\n",
    "plt.figure(figsize=(12, 10))\n",
    "corr = df_houses.corr()\n",
    "sns.heatmap(corr,\n",
    "        xticklabels=corr.columns,\n",
    "        yticklabels=corr.columns,\n",
    "        annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las features (X) y la variable objetivo (y)\n",
    "X = transformed_df_2[['GrLivArea', 'BedroomAbvGr', 'KitchenAbvGr', 'OverallCond', 'Pesos', 'Alley_Grvl', 'Alley_Pave', 'Alley_nan', 'WallMat_Concrete', 'WallMat_Wood', 'WallMat_nan']]\n",
    "y = transformed_df_2['SalePrice']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Inicializar el modelo de árboles de decisión\n",
    "model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Evaluar el modelo mediante validación cruzada\n",
    "cv_scores_mse = cross_val_score(model, X_train, y_train, cv=10, scoring='neg_mean_squared_error')\n",
    "cv_scores_r2 = cross_val_score(model, X_train, y_train, cv=10, scoring='r2')\n",
    "\n",
    "# Imprimir el rango del error cuadrático medio y del coeficiente de determinación\n",
    "print(f\"Error cuadrático medio: {-cv_scores_mse.max()} - {-cv_scores_mse.min()}\")\n",
    "print(f\"Coeficiente de determinación (R^2): {cv_scores_r2.min()} - {cv_scores_r2.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evstack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
